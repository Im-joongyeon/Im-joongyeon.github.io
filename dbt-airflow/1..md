---
description: DBT를 도입하게된 계기에 대해서 설명해보겠습니다.
---

# 1. 계기

## 들어가며

신입때 저에게 주어진 첫 업무는 블록체인의 원장 데이터를 가공하는 업무였습니다.

아래와 같이 "지표"라 부르는 데이터를 만들기위해서 원장 데이터를 가져와서 가공한 후에 API로 가져가기 좋게 인덱싱하는 업무였습니다.

<figure><img src="../.gitbook/assets/image (7).png" alt=""><figcaption></figcaption></figure>

회사에는 주식 및 블록체인 전문 리서처팀이 존재하며, 각 리서처들에의해서 2주마다 약 10\~ 15개 정도지표를 추가하는것을 목표로 했습니다.

이 기술 스택은 Golang, Postgres, Cron기반으로 Shell을작성해서 스케줄링했었습니다.

초기에는 파이프라인보다는 지표를 어떻게 어그리게이션 할 것인가에 대해 초점을 맞춰서 일을 했는데요,\
점점 지표가 많아지면서 개발해두었던 데이터 파이프라인에 대한 운영 업무가 쌓이면서 문제가 하나 하나 생겨났습니다.



## 문제점

1. 먼저 가장 문제가 되었던 부분은 운영에 이슈가 생길때마다 그 만큼 개발에 대한 시간을 할당할 수 없었는데요,  동일한 인력으로 동일한 개발 속도를 보장하기를 원했습니다.
2. 그리고 데이터에 대한 신뢰성 문제였습니다. 테이블들이 많아지고, 정규화된 테이블들이 의존성을 갖게 되면서 테이블을 만들어내는 스케줄러 하나가 오작동하거나, 오류를 일으키면 다른 프로세서가 정확하게 돌더라도 정확도가 떨어지는 문제가 생겼습니다.&#x20;
3. 지표가 점점 고도화 되면서 리서처와 개발자간의 커뮤니케이션 비용 증가가 문제되었습니다.



## 왜 DBT + Airflow여야 했을까?

### DBT

가장 고려되었떤점은 작업속도의 보장이였습니다. 리서처분들이 쿼리를 통해 데이터를 만들어내기를 원했습니다. 따라서 기존의 Golang기반보다는 쿼리 기반 베이스로 리서처들이 쿼리를 배우게하고 개발자들은 운영과 데이터 정합성 체크에 무게를 두고 싶어 했습니다. 따라서 SQL 중심의 접근이 가능한 DBT가 적합하다고 판단되었습니다.

### Airflow

Airflow를 통해서 각 테이블(모델)간의 순서를 보장할 수있고, 스케줄 타임과 성공 실패여부에 따라 재실행 하는 로직을 스케줄링하는게 Cron에 비해 훨씬 간편하고 강력했습니다. 또한 Airflow에서 제공하는 로깅을 통해 한 곳에서 로그파일을 관리할 수 있었습니다.







\








