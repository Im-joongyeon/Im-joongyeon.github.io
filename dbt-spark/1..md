---
description: 잘 쓰던 DBT를 Spark로 바꾸게 된 이유...
---

# 1. 계기

## 들어가며

지난 DBT + Airflow 마이그레이션 이후 잘 운영하고 있었습니다.

하지만 회사에서 전사 차원으로 메인넷 원장을 필요로하는 다른 여러 팀이 생겨났습니다.

그러다 데이터 플랫폼 팀이 신설되었고, 전사 차원에서 원장데이터를 HDFS로 관리하기로 결정이 되었습니다.



## 요구사항

우리팀은 이에 맞춰서 HDFS를 사용하도록 변경했어야했고, 기존의 원장데이터를 Postgres에서 HDFS에서 읽어오도록 변화시켜야 했습니다.

팀은 총 3명으로 2명은 원장데이터를 HDFS로 저장하고, 저의 역할은 HDFS로부터 원장데이터를 읽어와서 가공하는 업무를 맡았습니다.

이때부터는 신규지표를 개발하기보다는, 기존에 개발이 완료된 지표들에 대해서 스케줄링 운영 업무 위주로 돌아갔습니다.

기존에 사용하던 트리노 서버 자원은 64GB 워커 노드 4대 + 64GB Master 노드 1대면 300GB 정도 되는 RAM을 Spark와 같이 운영하는것은 운영부담도되고, 굳이 2가지 대용량 처리 툴을 같이 가지고 갈 필요가 없었습니다.



