---
description: O2팀에 처음 와서 한 일.
---

# 10배더 빠른 프로세서 만들기

## 들어가며

새로운 프로젝트에 합류했는데, 내용은 온체인에서 고래의 에어드랍이나, 각종 Defi를 통한 예치 상태를 온체인 데이터를 분석하여 수집하는 업무였습니다.&#x20;

기본적으로 원장데이터 구조를 보게되면&#x20;

<figure><img src="../.gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>

위와 같이 블록안에 다수의 트랜잭션데이터가 있고, 트랜잭션안에는 다수의 로그가 있습니다.\
Defi 분석을 위해서는 특정 Log를 필터링하고 가공하는 일이 필요합니다.

저는 팀이 만들어진지 1달이 넘은 시점에서 합류를 하게 되었습니다. 따라서 어느 정도 파이프라인이 구성되어 있었습니다.\
처음 팀에 합류해서 제일 먼저 한 일은 현재 구성되어있는 데이터 파이프라인을 이해하는데 집중했습니다.\
코드를 분석해보니 메인넷 노드로 부터 데이터를 가져오는 부분에서 비용 & 속도 적인 측면으로 개선할 수 있을거라고 생각했습니다.

## 기존 설계

1. 메인넷에서 신규 블록이 생성되면 RPC call(eth\_getBlockByHeight)
2. 블록에 대한 전체 블록데이터를 가져온다.
3. 데이터를 역직렬화 한다.
4. 블록안에 들어있는 전체 트랜잭션 데이터를 순회하면서 원하는 Log만 필터링한다.
5. 필터링된 Log들로부터 데이터 가공 한다.

## 어떻게 개선했는가?

기존 메인넷 노드에 사용하던 메서드는 eth\_getBlockByHeight였는데, eth\_getLogs로 변경함과 동시에 getLogs에는 다양한 파라미터들을 필터링 조건으로 추가 할 수 있습니다. (fromBlockNumber, toBlockNumber,  Topics, contract\_address등) 저는 노드에 요청하는 RPC call 방식을 변경하고, 여기에 각 로직으로 필터링하던 부분을 파라미터에 추가했습니다. 그리고 메인넷 노드 부하를 고려하여 약 1000개 블럭씩 배치로 작업하도록 변경했습니다.

## 개선점

1. 메인넷에 신규 블록이 생성되면 RPC call을 통해 필터링조건을 넣어서 요청(eth\_getLogs with 필터링 조건)
2. 필터링된 트랜잭션 정보만 가져온다.
3. 데이터 역직렬화 한다.
4. 데이터 가공 한다.

## 결과

메인넷 노드로부터 필터링된 데이터만 가져와서 불필요한 데이터 크기, 역직렬화를 줄일 수 있었습니다.\
그 결과 일(day)단위 적재에 30분 걸리던 프로세서를 3분으로 단축시킬 수 있었습니다.
